{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34b4dc7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2fe602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508263f",
   "metadata": {},
   "source": [
    "# Fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa72d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.f_utils.embedding_utils import load_embeddings, extract_embedding_single_study, extract_embeddings_from_img, extract_embeddings_from_text, _extract_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a4d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (377110,)\n"
     ]
    }
   ],
   "source": [
    "emb_per_image = load_embeddings(\"artifacts/img_embeddings/embeddings_per_image.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62146540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': 'p10000032',\n",
       " 'study_id': 's50414267',\n",
       " 'image_name': '02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       " 'embedding_image': array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "         0.06212181,  0.01484995], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_per_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a880c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (377110, 3)\n"
     ]
    }
   ],
   "source": [
    "metadata = load_embeddings(\"artifacts/img_embeddings/image_metadata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43a6f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p10000032', 's50414267',\n",
       "       '02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47668a",
   "metadata": {},
   "source": [
    "dict_final = {\n",
    "    \"study_index\": index do estudo,\n",
    "    \"study_id\": id do estudo,\n",
    "    \"patient_id\": id do paciente,\n",
    "    \"files_images\": [lista nomes de arquivos das imagens],\n",
    "    \"embedding_images\": [lista de embeddings das imagens para cada arquivo],\n",
    "    \"file_text\": arquivo do laudo,\n",
    "    \"embedding_text\": embedding do laudo\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8644156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_study_dataset(\n",
    "        emb_per_image, \n",
    "        study_ids_path=\"artifacts/embeddings/study_ids.npy\", \n",
    "        patient_ids_path=\"artifacts/embeddings/patient_ids.npy\",\n",
    "        text_emb_path=\"artifacts/embeddings/e_text.npy\",\n",
    "        labels_path=\"../dados/mimic/mimic-cxr-2.0.0-chexpert.csv\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Agrupa embeddings de imagens por estudo e combina com embeddings de texto e labels.\n",
    "    \n",
    "    Args:\n",
    "        emb_per_image: lista de dicion√°rios com embeddings por imagem\n",
    "        study_ids_path: caminho para arquivo com IDs dos estudos\n",
    "        patient_ids_path: caminho para arquivo com IDs dos pacientes\n",
    "        text_emb_path: caminho para arquivo com embeddings de texto\n",
    "        labels_path: caminho para arquivo CSV com labels CheXpert\n",
    "    \n",
    "    Returns:\n",
    "        Lista de dicion√°rios, um por estudo\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Carregar dados alinhados por √≠ndice\n",
    "    study_ids = load_embeddings(study_ids_path)\n",
    "    patient_ids = load_embeddings(patient_ids_path)\n",
    "    text_embeddings = load_embeddings(text_emb_path)\n",
    "    \n",
    "    # Carregar labels\n",
    "    df_labels = pd.read_csv(labels_path)\n",
    "    \n",
    "    # Identificar colunas de labels (excluindo subject_id e study_id)\n",
    "    label_columns = [col for col in df_labels.columns if col not in ['subject_id', 'study_id']]\n",
    "    \n",
    "    # Criar mapeamento study_id -> labels\n",
    "    study_labels_dict = {}\n",
    "    for _, row in df_labels.iterrows():\n",
    "        study_id = 's' + str(int(row['study_id']))\n",
    "        # Pegar labels onde o valor √© 1\n",
    "        labels = [col for col in label_columns if row[col] == 1.0]\n",
    "        study_labels_dict[study_id] = labels\n",
    "    \n",
    "    # Criar mapeamento study_id -> index\n",
    "    study_id_to_index = {sid: idx for idx, sid in enumerate(study_ids)}\n",
    "    \n",
    "    # Agrupar imagens por study_id\n",
    "    from collections import defaultdict\n",
    "    studies_dict = defaultdict(lambda: {\n",
    "        'files_images': [],\n",
    "        'embedding_images': []\n",
    "    })\n",
    "    \n",
    "    for img_data in emb_per_image:\n",
    "        study_id = img_data['study_id']\n",
    "        studies_dict[study_id]['files_images'].append(img_data['image_name'])\n",
    "        studies_dict[study_id]['embedding_images'].append(img_data['embedding_image'])\n",
    "        studies_dict[study_id]['patient_id'] = img_data['patient_id']\n",
    "    \n",
    "    # Construir lista final de estudos\n",
    "    result = []\n",
    "    for study_id, data in studies_dict.items():\n",
    "        # Buscar o √≠ndice do estudo\n",
    "        if study_id not in study_id_to_index:\n",
    "            print(f\"‚ö†Ô∏è Study ID {study_id} n√£o encontrado nos arquivos de embeddings\")\n",
    "            continue\n",
    "            \n",
    "        study_idx = study_id_to_index[study_id]\n",
    "        \n",
    "        study_dict = {\n",
    "            \"study_index\": study_idx,\n",
    "            \"study_id\": study_id,\n",
    "            \"patient_id\": patient_ids[study_idx],\n",
    "            \"files_images\": data['files_images'],\n",
    "            \"embedding_images\": data['embedding_images'],\n",
    "            \"file_text\": f\"{study_id}.txt\",\n",
    "            \"embedding_text\": text_embeddings[study_idx],\n",
    "            \"study_labels\": study_labels_dict.get(study_id, [])  # Labels do estudo ou lista vazia\n",
    "        }\n",
    "        result.append(study_dict)\n",
    "    \n",
    "    print(f\"‚úÖ {len(result)} estudos processados\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3df7d09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (227835,)\n",
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (227835,)\n",
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (227835, 1152)\n",
      "‚úÖ 227835 estudos processados\n",
      "\n",
      "\n",
      "Total de estudos: 227835\n",
      "Exemplo: {'study_index': 0, 'study_id': 's50414267', 'patient_id': 'p10000032', 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg', '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'], 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
      "        0.06212181,  0.01484995], dtype=float32), array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
      "        0.05352064,  0.01552592], dtype=float32)], 'file_text': 's50414267.txt', 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
      "       -0.07638288, -0.01550421], dtype=float32), 'study_labels': ['No Finding']}\n"
     ]
    }
   ],
   "source": [
    "studies_dataset = build_study_dataset(emb_per_image)\n",
    "print(f\"\\n\\nTotal de estudos: {len(studies_dataset)}\")\n",
    "print(f\"Exemplo: {studies_dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e48d2297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 0,\n",
       " 'study_id': 's50414267',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       "  '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'],\n",
       " 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "          0.06212181,  0.01484995], dtype=float32),\n",
       "  array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
       "          0.05352064,  0.01552592], dtype=float32)],\n",
       " 'file_text': 's50414267.txt',\n",
       " 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
       "        -0.07638288, -0.01550421], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0852817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da amostra de valida√ß√£o: 2278\n",
      "Dataset completo: 227835 estudos\n",
      "Dataset de valida√ß√£o: 2278 estudos\n",
      "Primeiro item da valida√ß√£o: s57812169\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Criar amostra de 1% do studies_dataset para valida√ß√£o\n",
    "\n",
    "# Definir seed para reprodutibilidade\n",
    "random.seed(42)\n",
    "\n",
    "# Calcular tamanho da amostra (1%)\n",
    "sample_size = int(0.01 * len(studies_dataset))\n",
    "print(f\"Tamanho da amostra de valida√ß√£o: {sample_size}\")\n",
    "\n",
    "# Criar amostra aleat√≥ria\n",
    "validation_dataset = random.sample(studies_dataset, sample_size)\n",
    "\n",
    "print(f\"Dataset completo: {len(studies_dataset)} estudos\")\n",
    "print(f\"Dataset de valida√ß√£o: {len(validation_dataset)} estudos\")\n",
    "print(f\"Primeiro item da valida√ß√£o: {validation_dataset[0]['study_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1322e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>56699142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000764</td>\n",
       "      <td>57375967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0    10000032  50414267          NaN           NaN            NaN    NaN   \n",
       "1    10000032  53189527          NaN           NaN            NaN    NaN   \n",
       "2    10000032  53911762          NaN           NaN            NaN    NaN   \n",
       "3    10000032  56699142          NaN           NaN            NaN    NaN   \n",
       "4    10000764  57375967          NaN           NaN            1.0    NaN   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         NaN       NaN          NaN           NaN   \n",
       "1                         NaN       NaN          NaN           NaN   \n",
       "2                         NaN       NaN          NaN           NaN   \n",
       "3                         NaN       NaN          NaN           NaN   \n",
       "4                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         1.0               NaN            NaN        NaN           NaN   \n",
       "1         1.0               NaN            NaN        NaN           NaN   \n",
       "2         1.0               NaN            NaN        NaN           NaN   \n",
       "3         1.0               NaN            NaN        NaN           NaN   \n",
       "4         NaN               NaN            NaN       -1.0           NaN   \n",
       "\n",
       "   Support Devices  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"../dados/mimic/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec625709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227827, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69b2791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_labels.columns[2:]  # Excluir subject_id e study_id\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e754bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de labels positivas (valor = 1):\n",
      "                         Label  Count  Percentage\n",
      "8                   No Finding  75455   33.119428\n",
      "13             Support Devices  66558   29.214272\n",
      "9             Pleural Effusion  54300   23.833874\n",
      "7                 Lung Opacity  51525   22.615844\n",
      "0                  Atelectasis  45808   20.106484\n",
      "1                 Cardiomegaly  44845   19.683795\n",
      "3                        Edema  27018   11.858998\n",
      "11                   Pneumonia  16556    7.266917\n",
      "2                Consolidation  10778    4.730783\n",
      "12                Pneumothorax  10358    4.546432\n",
      "4   Enlarged Cardiomediastinum   7179    3.151075\n",
      "6                  Lung Lesion   6284    2.758233\n",
      "5                     Fracture   4390    1.926901\n",
      "10               Pleural Other   2011    0.882687\n",
      "\n",
      "Total de estudos no dataset: 227827\n"
     ]
    }
   ],
   "source": [
    "# Contar quantos estudos t√™m cada label como positiva (valor 1)\n",
    "label_counts = {}\n",
    "\n",
    "for label in labels:\n",
    "    count = (df_labels[label] == 1.0).sum()\n",
    "    label_counts[label] = count\n",
    "\n",
    "# Criar DataFrame para visualizar melhor\n",
    "df_counts = pd.DataFrame(list(label_counts.items()), columns=['Label', 'Count'])\n",
    "df_counts['Percentage'] = (df_counts['Count'] / len(df_labels)) * 100\n",
    "df_counts = df_counts.sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"Contagem de labels positivas (valor = 1):\")\n",
    "print(df_counts)\n",
    "print(f\"\\nTotal de estudos no dataset: {len(df_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e9953",
   "metadata": {},
   "source": [
    "## dataset de valida√ß√£o com sklearn multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c75e29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2edf060",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_labels['study_id']\n",
    "y = df_labels.drop(['subject_id', 'study_id'], axis=1)\n",
    "\n",
    "for i in y.columns.to_list():\n",
    "    y[i] = np.where(y[i] == 1, 1, 0)\n",
    "    y[i] = y[i].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac478f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = x.values.reshape(-1, 1)  # Shape: (n_samples, 1)\n",
    "y_array = y.values                 # Shape: (n_samples, n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a46ae7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(x_array, y_array, test_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da93bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 225548 samples\n",
      "Test set: 2279 samples\n",
      "Labels shape: (225548, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6b3d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2279, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_val = df_labels[df_labels['study_id'].isin(X_test.flatten())]\n",
    "df_labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37314b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARA√á√ÉO: Dataset Original vs Dataset de Valida√ß√£o ===\n",
      "\n",
      "Dataset Original: 227,827 estudos\n",
      "Dataset Valida√ß√£o: 2,279 estudos\n",
      "Propor√ß√£o da valida√ß√£o: 1.00%\n",
      "\n",
      "Distribui√ß√£o por Labels:\n",
      "--------------------------------------------------------------------------------\n",
      "Atelectasis               | Original: 45,808 ( 20.1%) | Valida√ß√£o:  458 ( 20.1%) | Diff:  -0.0%\n",
      "Cardiomegaly              | Original: 44,845 ( 19.7%) | Valida√ß√£o:  448 ( 19.7%) | Diff:  -0.0%\n",
      "Consolidation             | Original: 10,778 (  4.7%) | Valida√ß√£o:  114 (  5.0%) | Diff:  +0.3%\n",
      "Edema                     | Original: 27,018 ( 11.9%) | Valida√ß√£o:  270 ( 11.8%) | Diff:  -0.0%\n",
      "Enlarged Cardiomediastinum | Original:  7,179 (  3.2%) | Valida√ß√£o:   78 (  3.4%) | Diff:  +0.3%\n",
      "Fracture                  | Original:  4,390 (  1.9%) | Valida√ß√£o:   44 (  1.9%) | Diff:  +0.0%\n",
      "Lung Lesion               | Original:  6,284 (  2.8%) | Valida√ß√£o:   63 (  2.8%) | Diff:  +0.0%\n",
      "Lung Opacity              | Original: 51,525 ( 22.6%) | Valida√ß√£o:  515 ( 22.6%) | Diff:  -0.0%\n",
      "No Finding                | Original: 75,455 ( 33.1%) | Valida√ß√£o:  755 ( 33.1%) | Diff:  +0.0%\n",
      "Pleural Effusion          | Original: 54,300 ( 23.8%) | Valida√ß√£o:  543 ( 23.8%) | Diff:  -0.0%\n",
      "Pleural Other             | Original:  2,011 (  0.9%) | Valida√ß√£o:   21 (  0.9%) | Diff:  +0.0%\n",
      "Pneumonia                 | Original: 16,556 (  7.3%) | Valida√ß√£o:  166 (  7.3%) | Diff:  +0.0%\n",
      "Pneumothorax              | Original: 10,358 (  4.5%) | Valida√ß√£o:  104 (  4.6%) | Diff:  +0.0%\n",
      "Support Devices           | Original: 66,558 ( 29.2%) | Valida√ß√£o:  666 ( 29.2%) | Diff:  +0.0%\n",
      "\n",
      "Total de labels positivas: | Original: 423,065 | Valida√ß√£o: 4,245\n"
     ]
    }
   ],
   "source": [
    "# Calcular contagens e propor√ß√µes para o dataset original (df_labels)\n",
    "print(\"=== COMPARA√á√ÉO: Dataset Original vs Dataset de Valida√ß√£o ===\\n\")\n",
    "\n",
    "original_counts = {}\n",
    "val_counts = {}\n",
    "\n",
    "for label in labels:\n",
    "    # Contagens dataset original\n",
    "    original_count = (df_labels[label] == 1).sum()\n",
    "    original_pct = (original_count / len(df_labels)) * 100\n",
    "    original_counts[label] = {'count': original_count, 'percentage': original_pct}\n",
    "    \n",
    "    # Contagens dataset valida√ß√£o\n",
    "    val_count = (df_labels_val[label] == 1).sum()\n",
    "    val_pct = (val_count / len(df_labels_val)) * 100\n",
    "    val_counts[label] = {'count': val_count, 'percentage': val_pct}\n",
    "\n",
    "# Criar DataFrame comparativo\n",
    "comparison_data = []\n",
    "for label in labels:\n",
    "    comparison_data.append({\n",
    "        'Label': label,\n",
    "        'Original_Count': original_counts[label]['count'],\n",
    "        'Original_Pct': original_counts[label]['percentage'],\n",
    "        'Validation_Count': val_counts[label]['count'],\n",
    "        'Validation_Pct': val_counts[label]['percentage'],\n",
    "        'Diff_Pct': val_counts[label]['percentage'] - original_counts[label]['percentage']\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(f\"Dataset Original: {len(df_labels):,} estudos\")\n",
    "print(f\"Dataset Valida√ß√£o: {len(df_labels_val):,} estudos\")\n",
    "print(f\"Propor√ß√£o da valida√ß√£o: {(len(df_labels_val)/len(df_labels))*100:.2f}%\\n\")\n",
    "\n",
    "print(\"Distribui√ß√£o por Labels:\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in df_comparison.iterrows():\n",
    "    print(f\"{row['Label']:25} | Original: {row['Original_Count']:6,} ({row['Original_Pct']:5.1f}%) | Valida√ß√£o: {row['Validation_Count']:4,} ({row['Validation_Pct']:5.1f}%) | Diff: {row['Diff_Pct']:+5.1f}%\")\n",
    "\n",
    "print(f\"\\n{'Total de labels positivas:':25} | Original: {df_comparison['Original_Count'].sum():6,} | Valida√ß√£o: {df_comparison['Validation_Count'].sum():4,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a8e3128",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset de valida√ß√£o do sklearn criado: 2279 estudos\n",
      "Dataset original (sklearn split): 2279 estudos\n",
      "Estudos encontrados no studies_dataset: 2279\n"
     ]
    }
   ],
   "source": [
    "# Filtrar studies_dataset para incluir apenas estudos que est√£o em df_labels_val\n",
    "balanced_validation_dataset = []\n",
    "\n",
    "# Converter df_labels_val['study_id'] para um conjunto de strings no formato correto\n",
    "val_study_ids = set('s' + str(int(study_id)) for study_id in df_labels_val['study_id'])\n",
    "\n",
    "# Filtrar studies_dataset\n",
    "for study in studies_dataset:\n",
    "    if study['study_id'] in val_study_ids:\n",
    "        balanced_validation_dataset.append(study)\n",
    "\n",
    "print(f\"‚úÖ Dataset de valida√ß√£o do sklearn criado: {len(balanced_validation_dataset)} estudos\")\n",
    "print(f\"Dataset original (sklearn split): {len(df_labels_val)} estudos\")\n",
    "print(f\"Estudos encontrados no studies_dataset: {len(balanced_validation_dataset)}\")\n",
    "\n",
    "# Verificar se todos os estudos foram encontrados\n",
    "missing_studies = len(df_labels_val) - len(balanced_validation_dataset)\n",
    "if missing_studies > 0:\n",
    "    print(f\"‚ö†Ô∏è {missing_studies} estudos n√£o foram encontrados no studies_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb20a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset de valida√ß√£o balanceado salvo em 'artifacts/datasets/balanced_validation_dataset.npy'\n",
      "Total de estudos salvos: 2279\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Salvar balanced_validation_dataset em artifacts/datasets\n",
    "\n",
    "# Criar diret√≥rio se n√£o existir\n",
    "os.makedirs(\"artifacts/datasets\", exist_ok=True)\n",
    "\n",
    "# Salvar o dataset de valida√ß√£o balanceado\n",
    "np.save(\"artifacts/datasets/balanced_validation_dataset.npy\", balanced_validation_dataset)\n",
    "\n",
    "print(f\"‚úÖ Dataset de valida√ß√£o balanceado salvo em 'artifacts/datasets/balanced_validation_dataset.npy'\")\n",
    "print(f\"Total de estudos salvos: {len(balanced_validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd19db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 0,\n",
       " 'study_id': 's50414267',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       "  '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'],\n",
       " 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "          0.06212181,  0.01484995], dtype=float32),\n",
       "  array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
       "          0.05352064,  0.01552592], dtype=float32)],\n",
       " 'file_text': 's50414267.txt',\n",
       " 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
       "        -0.07638288, -0.01550421], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_validation_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15bdde6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 2,\n",
       " 'study_id': 's53911762',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714.jpg',\n",
       "  'fffabebf-74fd3a1f-673b6b41-96ec0ac9-2ab69818.jpg'],\n",
       " 'embedding_images': [array([-0.02708424,  0.03832414,  0.00759004, ..., -0.01247607,\n",
       "          0.04935698,  0.01244616], dtype=float32),\n",
       "  array([-0.02862299,  0.03022767,  0.00633971, ..., -0.01368767,\n",
       "          0.04439005,  0.00473679], dtype=float32)],\n",
       " 'file_text': 's53911762.txt',\n",
       " 'embedding_text': array([ 0.00691437,  0.02525791, -0.01365044, ..., -0.04275578,\n",
       "        -0.04552101, -0.01475061], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_validation_dataset[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
