{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f553d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf49a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.f_utils.embedding_utils import load_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427b36b",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba82cb2",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e348abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (2279,)\n"
     ]
    }
   ],
   "source": [
    "val_dataset = load_embeddings('artifacts/datasets/balanced_validation_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83cd1a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 0,\n",
       " 'study_id': 's50414267',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       "  '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'],\n",
       " 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "          0.06212181,  0.01484995], dtype=float32),\n",
       "  array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
       "          0.05352064,  0.01552592], dtype=float32)],\n",
       " 'file_text': 's50414267.txt',\n",
       " 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
       "        -0.07638288, -0.01550421], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c903d",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8404a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>56699142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000764</td>\n",
       "      <td>57375967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0    10000032  50414267          NaN           NaN            NaN    NaN   \n",
       "1    10000032  53189527          NaN           NaN            NaN    NaN   \n",
       "2    10000032  53911762          NaN           NaN            NaN    NaN   \n",
       "3    10000032  56699142          NaN           NaN            NaN    NaN   \n",
       "4    10000764  57375967          NaN           NaN            1.0    NaN   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         NaN       NaN          NaN           NaN   \n",
       "1                         NaN       NaN          NaN           NaN   \n",
       "2                         NaN       NaN          NaN           NaN   \n",
       "3                         NaN       NaN          NaN           NaN   \n",
       "4                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         1.0               NaN            NaN        NaN           NaN   \n",
       "1         1.0               NaN            NaN        NaN           NaN   \n",
       "2         1.0               NaN            NaN        NaN           NaN   \n",
       "3         1.0               NaN            NaN        NaN           NaN   \n",
       "4         NaN               NaN            NaN       -1.0           NaN   \n",
       "\n",
       "   Support Devices  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"../dados/mimic/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311ae664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2279, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_study_ids = [study['study_id'] for study in val_dataset]\n",
    "# extrair 's' de 'study_id'\n",
    "val_study_ids = [int(study_id[1:]) for study_id in val_study_ids]\n",
    "\n",
    "# filtrar df_labels por val_study_ids\n",
    "df_labels_val = df_labels[df_labels['study_id'].isin(val_study_ids)]\n",
    "df_labels_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100aef5",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9bf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index('artifacts/vector_store/faiss_img.index')\n",
    "\n",
    "# Get the study indices from validation dataset\n",
    "val_study_indices = [item['study_index'] for item in val_dataset]\n",
    "\n",
    "# Create a new index with only the validation data\n",
    "# First, we need to get the vectors corresponding to the validation indices\n",
    "val_vectors = []\n",
    "for study_idx in val_study_indices:\n",
    "    # Reconstruct the vector from the original index\n",
    "    vector = index.reconstruct(study_idx)\n",
    "    val_vectors.append(vector)\n",
    "\n",
    "# Convert to numpy array\n",
    "val_vectors = np.array(val_vectors)\n",
    "\n",
    "# Create new FAISS index with filtered data\n",
    "filtered_index = faiss.IndexFlatIP(val_vectors.shape[1])  # or IndexFlatL2 depending on your original index\n",
    "filtered_index.add(val_vectors)\n",
    "\n",
    "# Save the filtered index\n",
    "# faiss.write_index(filtered_index, 'artifacts/vector_store/faiss_validation_filtered.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea431766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2279"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5237583",
   "metadata": {},
   "source": [
    "## IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8f65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings carregados com sucesso!\n",
      "üìä Formato dos dados: <class 'numpy.ndarray'>\n",
      "üìä Shape: (227835,)\n"
     ]
    }
   ],
   "source": [
    "ids = load_embeddings('artifacts/embeddings/study_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba5b643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s50414267'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8e99a",
   "metadata": {},
   "source": [
    "# Avalia√ß√£o\n",
    "\n",
    "O que queremos ver?  \n",
    "  \n",
    "1) jaccard indice: interseccao labels / uniao labels do estudo de entrada vs. estudo recuperado\n",
    "    - proporcao de estudos recuperados em que jaccard = 1 (deu match em todas as labels)\n",
    "    - m√©dia do indice de jaccard\n",
    "2) recall/f1 sei l√°:\n",
    "    - cria df_gabarito: todos os casos relevantes - em que todos os labels batem ou em que pelo menos 1 bate??\n",
    "        - df_gabarito √© o graund truth (GT) = casos relevantes\n",
    "        - casos retornados pelo rag = RC (rag cases) = predicted\n",
    "    - dos casos retornados pelo sistema rag quantos estao em df_gabarito?\n",
    "        - precision: casos relevantes retornados/casos retornados\n",
    "            - (RC intersecao com GT) / (all RC)\n",
    "        - recall: casos relevantes retornados/casos relevantes\n",
    "             - (RC intersecao com GT) / (all GT)\n",
    "3) m√©tricas por classe?\n",
    "\n",
    "\n",
    "Multiclasse:  \n",
    "Os valores de precis√£o e recall tamb√©m podem ser calculados para problemas de classifica√ß√£o com mais de duas classes. Para obter a **precis√£o** para uma determinada classe, *dividimos o n√∫mero de verdadeiros positivos pelo vi√©s do classificador em rela√ß√£o a essa classe (n√∫mero de vezes que o classificador previu a classe)*. Para calcular o **recall** para uma determinada classe, *dividimos o n√∫mero de verdadeiros positivos pela preval√™ncia dessa classe (n√∫mero de vezes que a classe ocorre na amostra de dados)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51b981",
   "metadata": {},
   "source": [
    "eu pensei em definir as metricas como:\n",
    "- `recall@k`: casos relevantes retornados nos top k/casos relevantes\n",
    "- `precision@k`: casos relevantes retornados/casos retornados\n",
    "- `jaccard_1@k`: propor√ßao dos top k casos em que jaccard=1\n",
    "- `jaccard@k`: media dos jaccard pros top k - qu√£o similares realmente s√£o os casos retornados\n",
    "- `NDGC@k`: Normalized Discounted Cumulative Gain (Ganho Cumulativo Descontado Normalizado) - avaliar o qu√£o bem um sistema classifica os itens por relev√¢ncia para um usu√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "791a4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.f_utils.evaluation import *\n",
    "from src.f_utils.rag_search import search_relevant_cases\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf0ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 0,\n",
       " 'study_id': 's50414267',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       "  '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'],\n",
       " 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "          0.06212181,  0.01484995], dtype=float32),\n",
       "  array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
       "          0.05352064,  0.01552592], dtype=float32)],\n",
       " 'file_text': 's50414267.txt',\n",
       " 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
       "        -0.07638288, -0.01550421], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2967d373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x7b0cf87d37b0> >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacfd87",
   "metadata": {},
   "source": [
    "## teste caso √∫nico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2012a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_index': 0,\n",
       " 'study_id': 's50414267',\n",
       " 'patient_id': 'p10000032',\n",
       " 'files_images': ['02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg',\n",
       "  '174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962.jpg'],\n",
       " 'embedding_images': [array([-0.02441736,  0.03465954,  0.00766411, ..., -0.01386673,\n",
       "          0.06212181,  0.01484995], dtype=float32),\n",
       "  array([-0.03161281,  0.03163843,  0.00890976, ..., -0.01544448,\n",
       "          0.05352064,  0.01552592], dtype=float32)],\n",
       " 'file_text': 's50414267.txt',\n",
       " 'embedding_text': array([-0.01413504,  0.01464215, -0.02659141, ..., -0.03464624,\n",
       "        -0.07638288, -0.01550421], dtype=float32),\n",
       " 'study_labels': ['No Finding']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e261814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([-0.0283,  0.0335,  0.0084,  ..., -0.0148,  0.0584,  0.0153])\n",
      "['s55135339', 's53583135', 's58230749', 's58051413', 's50867638']\n",
      "[1351 1370  384 1872  803]\n",
      "[{'study_id': 's54771176', 'labels': ['No Finding']}, {'study_id': 's51620571', 'labels': ['No Finding']}, {'study_id': 's54440894', 'labels': ['No Finding']}, {'study_id': 's59406568', 'labels': ['No Finding']}, {'study_id': 's55538863', 'labels': ['No Finding']}]\n",
      "[{'No Finding'}, {'No Finding'}, {'No Finding'}, {'No Finding'}, {'No Finding'}]\n",
      "{'No Finding'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision@k': 1.0,\n",
       " 'recall@k': 0.006622516556291391,\n",
       " 'jaccard_1@k': 1.0,\n",
       " 'jaccard@k': 1.0,\n",
       " 'ndcg@k': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para cada item de val_dataset, calcular os top k\n",
    "# k=2\n",
    "\n",
    "study = val_dataset[0]\n",
    "\n",
    "# Get the study index from the original index\n",
    "study_index = study['study_index']\n",
    "print(study_index)\n",
    "\n",
    "# Get the study vector from the original index\n",
    "study_vector = study['embedding_images'] # ajustei a fun√ß√£o para pular o primeiro caso\n",
    "\n",
    "emb_images = [torch.from_numpy(img) for img in study_vector]\n",
    "# Stacking para [N, D]\n",
    "emb_images = torch.stack(emb_images)  # [num_imagens, embedding_dim]\n",
    "\n",
    "# Pooling (m√©dia) ao longo das imagens\n",
    "emb_pool = emb_images.mean(dim=0)  # [embedding_dim]\n",
    "emb_pool = emb_pool / emb_pool.norm(dim=-1, keepdim=True)\n",
    "print(emb_pool)\n",
    "\n",
    "# Search the filtered index for the top k most similar vectors\n",
    "k = 5\n",
    "estudos, idxs = search_relevant_cases(emb_pool, filtered_index, ids, k)\n",
    "print(estudos) # study_ids\n",
    "print(idxs)    # study_indices\n",
    "\n",
    "# Get the labels of the top k most similar vectors\n",
    "study_top_k = []\n",
    "for i in idxs:\n",
    "    study_top_k.append({\n",
    "        'study_id': val_dataset[i]['study_index'],\n",
    "        'study_id': val_dataset[i]['study_id'],\n",
    "        'labels': val_dataset[i]['study_labels']\n",
    "    })\n",
    "print(study_top_k)\n",
    "\n",
    "list_set_top_k = [(set(study['labels'])) for study in study_top_k]\n",
    "print(list_set_top_k)\n",
    "\n",
    "# Get the ground truth labels for the study\n",
    "ground_truth_labels = set(study['study_labels'])\n",
    "print(ground_truth_labels)\n",
    "\n",
    "# Create a list of sets with all the labels from all the studys with at least one similar label\n",
    "from src.f_utils.mimic_labels import _get_gabarito_any\n",
    "\n",
    "gabarito = _get_gabarito_any(int(study['study_id'].replace('s', '')), df_labels_val)\n",
    "\n",
    "# Criar mapeamento study_id -> labels\n",
    "binary_cols = [col for col in df_labels_val.columns if col not in ['subject_id', 'study_id']]\n",
    "gabarito_list_set = []\n",
    "for _, row in gabarito.iterrows():\n",
    "    # Pegar labels onde o valor √© 1\n",
    "    labels = [col for col in binary_cols if row[col] == 1.0]\n",
    "    gabarito_list_set.append(set(labels))\n",
    "\n",
    "# Evalueate the results\n",
    "evaluate_single_query(ground_truth_labels, list_set_top_k, gabarito_list_set, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb4b01",
   "metadata": {},
   "source": [
    "## para todo o val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2b666bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2279/2279 [02:43<00:00, 13.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# para cada item de val_dataset, calcular os top k\n",
    "# k=2\n",
    "\n",
    "k=5\n",
    "\n",
    "# queries = [] # lista de sets de labels para cada estudo de consulta\n",
    "# retrived = [] # lista de listas de sets (resultados por query) retrieved[i][j] = labels do resultado j da query i\n",
    "\n",
    "results = [] # Salva todos os resultados nessa lista\n",
    "\n",
    "for study in tqdm(val_dataset):\n",
    "\n",
    "    # Get the embedding vector for the study\n",
    "    study_vector = study['embedding_images'] # ajustei a fun√ß√£o para pular o primeiro caso\n",
    "    \n",
    "    # Get the study vector from the original index\n",
    "    study_vector = study['embedding_images'] # ajustei a fun√ß√£o para pular o primeiro caso\n",
    "\n",
    "    emb_images = [torch.from_numpy(img) for img in study_vector]\n",
    "    # Stacking para [N, D]\n",
    "    emb_images = torch.stack(emb_images)  # [num_imagens, embedding_dim]\n",
    "\n",
    "    # Pooling (m√©dia) ao longo das imagens\n",
    "    emb_pool = emb_images.mean(dim=0)  # [embedding_dim]\n",
    "    emb_pool = emb_pool / emb_pool.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Search the filtered index for the top k most similar vectors\n",
    "    estudos, idxs = search_relevant_cases(emb_pool, filtered_index, ids, k)\n",
    "\n",
    "    # Cria o gabarito para mandar pra fun√ß√£o\n",
    "    gabarito = _get_gabarito_any(int(study['study_id'].replace('s', '')), df_labels_val)\n",
    "\n",
    "    # Criar mapeamento study_id -> labels\n",
    "    binary_cols = [col for col in df_labels_val.columns if col not in ['subject_id', 'study_id']]\n",
    "    gabarito_list_set = []\n",
    "    for _, row in gabarito.iterrows():\n",
    "        # Pegar labels onde o valor √© 1\n",
    "        labels = [col for col in binary_cols if row[col] == 1.0]\n",
    "        gabarito_list_set.append(set(labels))\n",
    "\n",
    "    \n",
    "    # Get the labels of the top k most similar vectors\n",
    "    study_top_k = []\n",
    "    for i in idxs:\n",
    "        study_top_k.append({\n",
    "            'study_id': val_dataset[i]['study_index'],\n",
    "            'study_id': val_dataset[i]['study_id'],\n",
    "            'labels': val_dataset[i]['study_labels']\n",
    "        })\n",
    "\n",
    "    ground_truth_labels = set(study['study_labels'])\n",
    "    list_set_top_k = [(set(s['labels'])) for s in study_top_k]\n",
    "\n",
    "    metrics = evaluate_single_query(ground_truth_labels, list_set_top_k, gabarito_list_set, k)\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "# M√©dia final das m√©tricas\n",
    "mean_metrics = {\n",
    "    m: np.mean([res[m] for res in results])\n",
    "    for m in results[0]\n",
    "}\n",
    "\n",
    "# results,mean_metrics = evaluate_dataset(queries, retrived, k=k) # avaliar o dataset inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc740c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@k': 0.35410267661254935,\n",
       " 'recall@k': 0.0021742397563200857,\n",
       " 'jaccard_1@k': 0.27283896445809563,\n",
       " 'jaccard@k': 0.3062467874380994,\n",
       " 'ndcg@k': 0.41437501059103277}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cfff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@k': 1.0,\n",
       " 'recall@k': 0.006622516556291391,\n",
       " 'jaccard_1@k': 1.0,\n",
       " 'jaccard@k': 1.0,\n",
       " 'ndcg@k': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
